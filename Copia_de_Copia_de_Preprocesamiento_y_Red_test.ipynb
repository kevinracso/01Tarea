{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de Copia de Preprocesamiento_y_Red_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kevinracso/01Tarea/blob/master/Copia_de_Copia_de_Preprocesamiento_y_Red_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLH9JNxiOBYe",
        "colab_type": "text"
      },
      "source": [
        "## Permite importar archivos desde Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIkIFkQqFfZC",
        "colab_type": "code",
        "outputId": "78eb3995-f82f-41ff-a594-b888068f8c5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzWNSL-6ONhQ",
        "colab_type": "text"
      },
      "source": [
        "## Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R8MbxbinZwWz",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "#%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import matplotlib.cm as cm\n",
        "from skimage import io, img_as_float\n",
        "import scipy.interpolate as itp\n",
        "\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OpDHxNDxZwW8",
        "outputId": "312b9a95-f87e-41cd-dffc-0cc80126c754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "from time import time\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "from warnings import simplefilter\n",
        "\n",
        "simplefilter(action='ignore', category=FutureWarning) # Comando para ignorar los warnings\n",
        "\n",
        "\n",
        "import keras  # Importando la libreria keras\n",
        "from keras.models import Sequential  \n",
        "from keras.layers import Dense, Dropout, Flatten # Comandos de keras que importan las capas dense, dropout y flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D # Comandos de keras que importan las capas convolucionales y maxpooling2D\n",
        "from keras import backend as K\n",
        "from keras.layers.advanced_activations import LeakyReLU"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06HlLvnFOT1y",
        "colab_type": "text"
      },
      "source": [
        "## Cargar base de datos "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XcswmPjvZwXE",
        "colab": {}
      },
      "source": [
        "# Cargando base de datos Alerce.\n",
        "data = pd.read_pickle('/content/drive/My Drive/Supernova/ALERCE_stamps.pkl') # Base de datos original\n",
        "#data = pd.read_pickle('/content/drive/My Drive/Supernova/ALERCE_stamps_1k.pkl') # Base de datos reducida"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EVlvCKwPZwXJ",
        "colab": {}
      },
      "source": [
        "imgs = data['images'] # Lista de 31727 imagenes\n",
        "labels = data['labels'] # Lista de 31727 labels\n",
        "\n",
        "img_0 = imgs[0] # Primera imagen de imgs, ndarray 63x63, 3 canales\n",
        "label_0 = labels[0] # Primer label, entero"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bPOfFmFtZwXO",
        "outputId": "ef2963ee-6b97-44c2-ed25-97c14bebe0cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.shape(imgs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31727,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToTRDcMYOcmu",
        "colab_type": "text"
      },
      "source": [
        "## Desechar imágenes no cuadradas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VGClQnAJZwXT",
        "colab": {}
      },
      "source": [
        "shap_def = (63, 63, 3) # Estructura correcta de imagenes, cuadradas, 3 canales\n",
        "\n",
        "img_sq = [] # Inicializar lista vacia para almacenar imagenes que tienen\n",
        "            # estructura correcta\n",
        "label_sq = [] # Inicializar lista vacia para almacenar labels de imagenes que\n",
        "              # tienen estructura correcta\n",
        "    \n",
        "for j in list(range(len(imgs))): # recorrer imagenes\n",
        "    #print('Revisando si la imagen '+str(j)+' es cuadrada')\n",
        "    if np.shape(imgs[j]) == shap_def: # si tiene estructura correcta, agregar\n",
        "        \n",
        "        img_sq.append(imgs[j])\n",
        "        label_sq.append(labels[j])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XxmZdhQOhcP",
        "colab_type": "text"
      },
      "source": [
        "## Normalizar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ziWvlTxDZwXg",
        "colab": {}
      },
      "source": [
        "img_sq = np.asarray(img_sq)\n",
        "label_sq = np.asarray(label_sq)\n",
        "\n",
        "# Funcion auxiliar que normaliza UNA matriz\n",
        "def Norm_Data_matrix(matrix):\n",
        "    max_data = np.nanmax(matrix)\n",
        "    min_data = np.nanmin(matrix)\n",
        "    Norm_matrix = (matrix-min_data)/(max_data-min_data)\n",
        "    return Norm_matrix\n",
        "\n",
        "# Normalizacion de las imagenes\n",
        "img_norm = []\n",
        "for i in range(len(img_sq)):\n",
        "    muestra = img_sq[i]\n",
        "    #print('Normalizando muestra ' + str(i))\n",
        "    muestra[:, :, 0] = Norm_Data_matrix(muestra[:, :, 0])\n",
        "    muestra[:, :, 1] = Norm_Data_matrix(muestra[:, :, 1])\n",
        "    muestra[:, :, 2] = Norm_Data_matrix(muestra[:, :, 2])\n",
        "    img_norm.append(muestra)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QcYYqYNtZwXo",
        "colab": {}
      },
      "source": [
        "img_norm = np.array(img_norm) # Convertir a arreglo numpy\n",
        "\n",
        "nan_index = np.argwhere(np.isnan(img_norm))\n",
        "#print('Indices de nan en arreglo normalizado', nan_index)\n",
        "\n",
        "img_no_nan = np.nan_to_num(img_norm) # Convertir nan a cero\n",
        "\n",
        "nonan_index = np.argwhere(np.isnan(img_no_nan))\n",
        "#print('Indices de nan en arreglo al eliminar nan', nonan_index)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aol5xZIDZwXt",
        "outputId": "e8bf19f8-020b-45d2-ca72-a68a2e70876c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.shape(img_no_nan) # Dimensiones de la base corregida"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31228, 63, 63, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YMveuhckbxA",
        "colab_type": "text"
      },
      "source": [
        "## Balance de Clases, definir conjuntos de train, val, y test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQjqtVSjJ7sX",
        "colab_type": "code",
        "outputId": "dda67776-1f62-447d-9216-ef086aa11a56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\"Objetos a tratar\"\n",
        "\n",
        "\" Clases = {0: 'AGN', 1:'SN', 2:'VS', 3:'asteroid', 4:'bogus'}\" \n",
        "\"AGN: Active Galactic Nuclei\"\n",
        "\"SN: Supernova\"\n",
        "\"VS: Variable Star\"\n",
        "\"bogus: Artifacts\"\n",
        "\n",
        "img_no_nan # imagenes, np array\n",
        "label_sq # labels, np array\n",
        "\n",
        "unique, counts = np.unique(label_sq, return_counts=True)\n",
        "class_counter = dict(zip(unique, counts)) # muestra cuantas veces se repite cada clase\n",
        "print('Numero de muestras por clase:', class_counter)\n",
        "\n",
        "#test = np.concatenate((img_no_nan, label_sq), axis=0)\n",
        "#test_1 = np.concatenate((img_no_nan, label_sq), axis=1)\n",
        "\n",
        "s_index = np.arange(label_sq.shape[0]) # indexar arreglos\n",
        "\n",
        "np.random.shuffle(s_index) # revolver\n",
        "\n",
        "# label_sq.shape[0], label_sq.shape\n",
        "\n",
        "img_no_nan = img_no_nan[s_index] # reemplazar arreglos originales por arreglos revueltos\n",
        "label_sq = label_sq[s_index]\n",
        "\n",
        "\"Encontrar ubicaciones de todos los tipos de objeto\"\n",
        "\n",
        "agn_ind = np.squeeze(np.argwhere(label_sq == 0))\n",
        "sn_ind = np.squeeze(np.argwhere(label_sq == 1))\n",
        "vs_ind = np.squeeze(np.argwhere(label_sq == 2))\n",
        "ast_ind = np.squeeze(np.argwhere(label_sq == 3))\n",
        "bog_ind = np.squeeze(np.argwhere(label_sq == 4))\n",
        "\n",
        "\"Una lista para cada tipo de objeto\"\n",
        "\n",
        "img_AGN = img_no_nan[agn_ind]\n",
        "img_SN = img_no_nan[sn_ind]\n",
        "img_VS = img_no_nan[vs_ind]\n",
        "img_AST = img_no_nan[ast_ind]\n",
        "img_bog = img_no_nan[bog_ind]\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numero de muestras por clase: {0: 8721, 1: 987, 2: 9772, 3: 9797, 4: 1951}\n",
            "[0 0 0 ... 0 0 0]\n",
            "[ True  True  True ...  True  True  True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FxnxFw9yZwYO",
        "colab": {}
      },
      "source": [
        "# Separación de la base de datos en un conjunto de entrenamiento y validación.\n",
        "train_size = int(len(img_no_nan)*.75) # Definiendo el tamaño del conjunto de entrenamiento con los requisitos solicitados \n",
        "train_total = int(len(img_no_nan)) # Tamaño total del conjunto original.\n",
        "x_train = img_no_nan[0:train_size,:] # Nuevo conjunto horizontal de entrenamiento.\n",
        "x_val = img_no_nan[train_size:train_total,:] # Conjunto de validacion horizontal. (imagenes)\n",
        "y_train = y_data[:train_size] # Nuevo conjunto vertical de entrenamiento. (clases)\n",
        "y_val = y_data[train_size:] # Conjunto de validacion vertical (clases)\n",
        "\n",
        "input_shape = (img_rows, img_cols, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BK3giLeCOmhC",
        "colab_type": "text"
      },
      "source": [
        "# Red Neuronal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qqu7O3xdOtK1",
        "colab_type": "text"
      },
      "source": [
        "## Preliminares"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tCzIXeWmZwXy",
        "colab": {}
      },
      "source": [
        "# Para poder procesar las clases es necesario pasarlas a one hot encoding\n",
        "\n",
        "# Funcion para tener las clases como one hot encoding\n",
        "def one_hot(a, num_classes):\n",
        "    return np.squeeze(np.eye(num_classes)[a.reshape(-1)])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-5Am88gAZwX3",
        "colab": {}
      },
      "source": [
        "onehot_labels = one_hot(label_sq, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9gzGxYFuZwX8",
        "colab": {}
      },
      "source": [
        "batch_size = 128 # Definiendo el tamaño de los batches\n",
        "num_classes = 5 # Numero de clases del conjunto\n",
        "epochs = 12 # Cantidad de epocas\n",
        "#pool_value = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_ajOT8R5ZwYB",
        "colab": {}
      },
      "source": [
        "# input image dimensions\n",
        "img_rows, img_cols = 63, 63  # Definiendo las filas y columnas de las imagenes\n",
        "y_data = onehot_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NYHyUjQ6ZwYJ",
        "outputId": "f21daa94-a306-4b19-8ce9-628d005c7421",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.shape(img_no_nan)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31228, 63, 63, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZgYlnel9oqz",
        "colab_type": "text"
      },
      "source": [
        "## Al parecer este bloque no hace nada a las variables x_train y similares"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "olLRBnLeZwYY",
        "outputId": "a896c807-5609-4d4c-f25d-ac0bf9f9eb73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_val = x_val.astype('float32')\n",
        "x_train /= 255\n",
        "x_val /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_val.shape[0], 'test samples')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (23421, 63, 63, 3)\n",
            "23421 train samples\n",
            "7807 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JjCUN78O9Jr",
        "colab_type": "text"
      },
      "source": [
        "## Configurar Red!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_jCRRf4sZwYj",
        "outputId": "c4810021-1d31-462c-e91c-e3cb99683698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "\"\"\" PROGRAMACIÓN DE LA RED NEURONAL CONVOLUCIONAL!!\n",
        "    En los siguientes bloques se configura una CNN usando la estructura entregada en el paper.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\"Convierten a one hot encoding\"\n",
        "y_train_1 = keras.utils.to_categorical(y_train, num_classes) # Categorización de las muestras del conjunto vertical de entrenamiento.\n",
        "y_val_1 = keras.utils.to_categorical(y_val, num_classes) # Categorización de las muestras del conjunto vertical de prueba.\n",
        "\"Convierten a one hot encoding\"\n",
        "\n",
        "\n",
        "time_i = time()\n",
        "model = Sequential() # Inicio de la configuracion del clasificador , a partir de este punto se le añadiran las capas que conformaran la CNN\n",
        "model.add(Conv2D(32, kernel_size=(4, 4), # Añadiendo una capa convolucional al modelo con un kernel  de 3x3 \n",
        "                 activation = None, # Con un funcion de activacion relu  y las dimensiones configuradas en el bloque anterior\n",
        "                 input_shape=input_shape)) \n",
        "model.add(Conv2D(32, (3, 3), activation = None)) # Añadiendo otra capa convolucional  con una funcion de activacion relu\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),strides = 2)) # Utilizando el método maxpooling en esta red.\n",
        "model.add(Conv2D(64, (3, 3), activation = None))\n",
        "model.add(Conv2D(64, (3, 3), activation = None))\n",
        "model.add(Conv2D(64, (3, 3), activation = None))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides = 2))\n",
        "#model.add(Dropout(0.5)) # Añadiendo Dropout a la red\n",
        "model.add(Flatten()) # Este comando remueve todas las dimensiones de un tensor exceptuano una.\n",
        "#model.add(Dense(128, activation=LeakyReLU)) # En esta capa se implementa la funcion de activacion relu a la capa anterior de la la red neuronal. \n",
        "model.add(Dense(64)) # 64 salidas\n",
        "model.add(LeakyReLU()) # LeakyReLU\n",
        "model.add(Dropout(0.5)) # Se agrega la tecnica de Dropout para abordar el overfitting.\n",
        "model.add(Dense(64))\n",
        "model.add(LeakyReLU()) # LeakyReLU\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax')) # Se aplica a la red siendo esta vez usando la funcion softmax.\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy']) # Con este coomando se configura el modelo para el entrenamiento.\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HidLNjbwPBg2",
        "colab_type": "text"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dd-n-8b5ZwYn",
        "outputId": "99444fb7-6de8-486d-b19f-b4561e9ec763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "# Entrenamiento del modelo\n",
        "\n",
        "model_train = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_val, y_val)) # Comando para entrenar el modelo.\n",
        "model_train\n",
        "score = model.evaluate(x_val, y_val, verbose=0) # Con este comando se obtiene el valor de perdida y de las metricas en el modo de prueba.\n",
        "time_f = time()\n",
        "time_execution = time_f - time_i # Con este comando se obtiene el valor de perdida y de las metricas en el modo de prueba.\n",
        "print('Valid loss:', score[0]) # Se imprime la perdida para la prueba realizada.\n",
        "print('Valid accuracy:', score[1]) # Se imprimre el accuracy para la prueba realizada.\n",
        "print('Tiempo de entrenamiento ' + str(time_execution))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 23421 samples, validate on 7807 samples\n",
            "Epoch 1/12\n",
            " 7296/23421 [========>.....................] - ETA: 24s - loss: 1.4488 - acc: 0.3076"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-f6a3fdf4865c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           validation_data=(x_val, y_val)) # Comando para entrenar el modelo.\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Con este comando se obtiene el valor de perdida y de las metricas en el modo de prueba.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPCzQgKuabhr",
        "colab_type": "code",
        "outputId": "52106f43-6b65-43e3-91fd-c119d4828b4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([0, 3, 1, 2, 4, 1, 0, 4])\n",
        "# x = np.reshape(x, (4, 25))\n",
        "print(x)\n",
        "\n",
        "\n",
        "ind = np.squeeze(np.argwhere(x%7 == 0))\n",
        "print(ind)\n",
        "\n",
        "#y = np.squeeze(x[ind])\n",
        "y = x[ind]\n",
        "print(y)\n",
        "\n",
        "z = keras.utils.to_categorical(x, 5)\n",
        "\n",
        "print(z)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 3 1 2 4 1 0 4]\n",
            "[0 6]\n",
            "[0 0]\n",
            "[[1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}